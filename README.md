# agent-ready-k8s

> **AI-gesteuerte Kubernetes-Plattform-Vorlage**  
> Multi-Tenant SaaS-Plattform mit Self-Service Tenant-Erstellung, Hot-Reload-Konfiguration und Enterprise-Grade-Architektur.

---

## üìä Architektur-√úbersicht

### **Tabelle 1: Datenspeicherung - Wo liegt was?**

| Datentyp | Speicherort | Beispiel | Warum hier? | Warum NICHT woanders? |
|----------|-------------|----------|-------------|-----------------------|
| **Tenant-Metadaten** | PostgreSQL (App-DB) | `org_name="ACME Corp"`, `owner_email` | ‚úÖ Flexible Queries (JOIN, Filter)<br>‚úÖ Backup/Migration einfach<br>‚úÖ Unabh√§ngig von K8s | ‚ùå etcd = kein SQL, K8s-intern<br>‚ùå Verlust bei Cluster-Migration |
| **K8s-Konfiguration** | etcd (K8s interne DB) | Namespace, RBAC, Quotas | ‚úÖ K8s liest/schreibt direkt<br>‚úÖ Millisekunden-Latenz<br>‚úÖ Distributed Consensus (HA) | ‚ùå PostgreSQL = zu langsam f√ºr K8s<br>‚ùå Keine Strong Consistency |
| **User-Daten (Notizen)** | PostgreSQL (im Pod im Namespace) | `note_id=123`, `content="Meeting Notes"` | ‚úÖ ACID-Transaktionen<br>‚úÖ Komplexe Queries<br>‚úÖ Bew√§hrte Backups (pg_dump) | ‚ùå etcd = Max 1.5 MB pro Key<br>‚ùå Nicht f√ºr App-Daten designed |
| **Secrets (Passw√∂rter)** | etcd (verschl√ºsselt) ODER Azure Key Vault | DB-Passwort, API-Keys | ‚úÖ K8s-native Injection (envFrom)<br>‚úÖ Rotation via ESO<br>‚úÖ Hardware-backed (HSM) | ‚ùå PostgreSQL = Sicherheitsrisiko<br>‚ùå Git = NIEMALS Secrets committen |

---

### **Tabelle 2: Tenant-Erstellung (Self-Service wie Azure)**

| Schritt | Aktion | Wo gespeichert? | Wer macht es? | Latenz |
|---------|--------|-----------------|---------------|--------|
| **1. User registriert sich** | User klickt "Create Organization" | Browser ‚Üí Backend API | User | - |
| **2. Metadaten speichern** | `INSERT INTO organizations (name, owner)` | PostgreSQL | Backend API | ~10ms |
| **3. Namespace erstellen** | `kubectl create namespace org-acme` | etcd (via K8s API) | Backend ‚Üí K8s API | ~50ms |
| **4. RBAC erstellen** | `kubectl create rolebinding admin` | etcd | Backend ‚Üí K8s API | ~20ms |
| **5. ResourceQuota** | CPU=10, Memory=20Gi | etcd | Backend ‚Üí K8s API | ~20ms |
| **6. NetworkPolicy** | Deny-all Baseline | etcd | Backend ‚Üí K8s API | ~20ms |

**Gesamt:** ~120ms = **Self-Service wie Azure** ‚úÖ

---

### **Tabelle 3: Hot-Reload Config (AI-Threshold Beispiel)**

| Option | Wo gespeichert? | Hot-Reload? | Latenz | Warum nutzen? | Warum NICHT nutzen? |
|--------|-----------------|-------------|--------|---------------|---------------------|
| **PostgreSQL (Polling)** | `settings` Tabelle | ‚ö†Ô∏è JA (5s Verz√∂gerung) | 0-5s | ‚úÖ Einfach, keine Extra-Dependencies | ‚ùå DB-Last, nicht Echtzeit |
| **Redis Pub/Sub** | Redis Key + PUBLISH | ‚úÖ JA | <100ms | ‚úÖ Echtzeit<br>‚úÖ Multi-Pod Sync | ‚ö†Ô∏è Extra Dependency |
| **ConfigMap + Reloader** | K8s ConfigMap | ‚ö†Ô∏è JA (Restart) | ~15s | ‚úÖ K8s-native, GitOps | ‚ùå Pod-Restart = Downtime |
| **etcd (direkt)** | etcd Key + Watch API | ‚úÖ JA | <50ms | ‚úÖ K8s-intern vorhanden | ‚ùå Komplex, Sicherheitsrisiko<br>‚ùå Nicht f√ºr Apps designed |

**Empfehlung:** PostgreSQL (Source of Truth) + Redis (Hot-Reload) ‚úÖ

---

### **Tabelle 4: Warum NICHT etcd f√ºr App-Config?**

| Problem | Konsequenz | Alternative |
|---------|------------|-------------|
| Nicht f√ºr App-Daten designed | etcd = K8s Control Plane Storage | PostgreSQL f√ºr App-Daten |
| Komplexe RBAC | Pod braucht K8s API-Zugriff = Sicherheitsrisiko | Redis = App-Level, kein K8s-Zugriff n√∂tig |
| Keine native Watch-API f√ºr Apps | 50+ Zeilen Boilerplate-Code | Redis Pub/Sub = 5 Zeilen Code |
| Backup/Audit schwierig | etcd-Backup = gesamter Cluster (GB) | PostgreSQL-Backup = nur deine Daten (MB) |
| Skalierungs-Limit | Max 8 GB empfohlen | PostgreSQL+Redis = TB-f√§hig |
| Vendor Lock-In | K8s-spezifisch | PostgreSQL+Redis = √ºberall nutzbar |

---

### **Tabelle 5: Dein System vs. Azure DevOps**

| Feature | Dein K8s-System | Azure DevOps | Vorteil |
|---------|-----------------|--------------|---------|
| **Multi-Tenancy** | Namespace pro Org | Azure Org/Projects | ‚úÖ Gleich (beide Self-Service) |
| **Tenant-Erstellung** | API ‚Üí K8s Operator | Azure Portal ‚Üí ARM | ‚úÖ Gleich (~100ms) |
| **Hot-Reload Config** | PostgreSQL + Redis Pub/Sub | Azure App Configuration + Event Grid | ‚úÖ Dein System schneller (<100ms vs. ~500ms) |
| **Feature Flags** | Custom (Redis/DB) | Native (Azure App Config) | ‚ö†Ô∏è Azure besser (Out-of-Box) |
| **Kosten** | $0 (self-hosted) | $1-10/Monat (managed) | ‚úÖ Dein System g√ºnstiger |
| **Vendor Lock-In** | ‚ùå NEIN (Open Source) | ‚úÖ JA (Azure-only) | ‚úÖ Dein System portabel |
| **Secrets Management** | ESO ‚Üí Key Vault/Vault | Azure Key Vault (native) | ‚úÖ Gleich |

---

## üìä Tabelle 6: Workflow-√úbersicht (End-to-End) - NACH SPEICHER-BEREICHEN

---

### **üóÑÔ∏è BEREICH A: TENANT & INFRASTRUKTUR (PostgreSQL + etcd)**
> **Was:** Org-Erstellung, K8s-Ressourcen (Namespace, Quotas, Network)  
> **Wof√ºr:** Grundlegende Tenant-Isolation und Ressourcen-Limits

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | ‚ö†Ô∏è GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **1a. Registrierung** | "Create Org: ACME Corp" | Backend ‚Üí PostgreSQL + K8s API | PostgreSQL + etcd | ~120ms | **Org-Erstellung:**<br>‚Ä¢ DB: `organizations` (id, name, owner_email)<br>‚Ä¢ K8s: Namespace `org-acme` | **SAGA-Pattern:**<br>‚Ä¢ Status: `PENDING` ‚Üí K8s create ‚Üí `COMMITTED`<br>‚Ä¢ Bei Fehler: `FAILED` + kompensierende L√∂schung<br><br>**Idempotenz:**<br>‚Ä¢ Operation-ID in DB + K8s-Annotation<br>‚Ä¢ Verhindert doppelte Org bei Retry |
| **1b. Initial Storage** | System setzt Default: 10GB | Backend ‚Üí K8s API | etcd + PostgreSQL | ~20ms | **Storage Init:**<br>‚Ä¢ K8s: `ResourceQuota` (storage: 10Gi)<br>‚Ä¢ DB: `service_configs` (Audit-Log) | **Namespace-Gate:**<br>‚Ä¢ Policy blockt Pods bis Label `isolation-ready=true` gesetzt<br>‚Ä¢ Verhindert Race-Conditions |
| **1c. Initial CPU/Memory** | System setzt Default: CPU=10, Memory=20Gi | Backend ‚Üí K8s API | etcd + PostgreSQL | ~20ms | **Compute Init:**<br>‚Ä¢ K8s: `ResourceQuota` (cpu: 10, memory: 20Gi)<br>‚Ä¢ DB: `service_configs` (Audit-Log) | **Race-free Isolation:**<br>‚Ä¢ Onboarding-Job setzt `isolation-ready=true` NACH:<br>&nbsp;&nbsp;1. Default-Deny NetworkPolicy<br>&nbsp;&nbsp;2. ResourceQuotas<br>&nbsp;&nbsp;3. RBAC |
| **1d. NetworkPolicy** | System aktiviert Isolation | Backend ‚Üí K8s API | etcd | ~20ms | **Network Init:**<br>‚Ä¢ K8s: `NetworkPolicy` (deny-all baseline) | **Cluster-Policy-Gate:**<br>‚Ä¢ Kyverno/OPA Policy enforced:<br>‚Ä¢ Pods in neuen Namespaces = `Pending` bis `isolation-ready=true` |

---

### **üîê BEREICH B: AUTHENTIFIZIERUNG (JWT Token)**
> **Was:** User-Login, Token-Generierung  
> **Wof√ºr:** Zugriffskontrolle, Session-Management

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | ‚ö†Ô∏è GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **2. Login** | Email + Passwort | JWT Token via OAuth2-Proxy | - (ephemeral) | ~50ms | **Auth:**<br>‚Ä¢ Token: `org_id=123`, `user_role=admin`, `permissions=[...]` | **Sofort-Widerruf:**<br>‚Ä¢ **Option A:** Key-Rotation (kurze TTL + Signier-Keywechsel)<br>‚Ä¢ **Option B:** JTI-Denylist (Redis/DB) f√ºr Notf√§lle<br><br>**TTL-Strategie:**<br>‚Ä¢ Access-Token: 1h (wie Azure AD)<br>‚Ä¢ Refresh-Token: 90d (sliding window)<br><br>**Security:**<br>‚Ä¢ Token enth√§lt `jti` (JWT ID) f√ºr Tracking<br>‚Ä¢ Bei Compromise: `jti` in Denylist ‚Üí Token ung√ºltig |

---

### **üì¶ BEREICH C: BUSINESS-DATEN (PostgreSQL)**
> **Was:** User-Daten (Projekte, Notizen, Dokumente)  
> **Wof√ºr:** Eigentliche App-Funktionalit√§t

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | ‚ö†Ô∏è GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **3. Projekt erstellen** | "Create Project: Notes App" | Backend ‚Üí PostgreSQL | PostgreSQL | ~10ms | **Project:**<br>‚Ä¢ Tabelle: `projects` (id, name, org_id) | **Row-Level Security (RLS):**<br>‚Ä¢ PostgreSQL-Feature aktiviert<br>‚Ä¢ Automatische Filter nach `org_id`<br>‚Ä¢ Backend setzt: `SET app.current_org = 123`<br><br>**Policy:**<br>‚Ä¢ Tenant-Isolation auf DB-Ebene<br>‚Ä¢ Queries sehen nur eigene Org-Daten |
| **4. Notiz schreiben** | "Meeting with customer" | Backend ‚Üí PostgreSQL | PostgreSQL | ~10ms | **Data:**<br>‚Ä¢ Tabelle: `notes` (id, project_id, content) | **RLS + PITR:**<br>‚Ä¢ **RLS:** Automatische Filter nach `org_id`<br>‚Ä¢ **PITR:** WAL-Archiving aktiv<br>‚Ä¢ **Restore-Runbook:** 5-Minuten-RPO<br>‚Ä¢ **Backup:** pg_dump t√§glich + WAL kontinuierlich |

---

### **‚öôÔ∏è BEREICH D: SERVICE-CONFIGS (PostgreSQL + Redis Hot-Reload)**
> **Was:** App-Einstellungen (AI-Threshold, Email-Retries, Webhooks, Feature-Flags)  
> **Wof√ºr:** Hot-Reload Config ohne Pod-Restart

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | ‚ö†Ô∏è GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **5a. AI-Threshold** | Slider: 0.75 ‚Üí 0.90 | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **AI Config:**<br>‚Ä¢ DB: `service_configs` (service='ai', key='threshold', value='0.90', version=5)<br>‚Ä¢ Redis: `PUBLISH config:ai:threshold "version=5"`<br>‚Ä¢ Audit: `config_history` | **Versionierung:**<br>‚Ä¢ Monoton steigende Version-Nummer<br>‚Ä¢ Pub/Sub tr√§gt nur Version (kein Value)<br>‚Ä¢ Pod holt Value aus DB bei Version-Erh√∂hung<br><br>**Resilienz:**<br>‚Ä¢ Warm-Load beim Start (alle Configs aus DB)<br>‚Ä¢ Reconcile alle 5-10 min (falls PUBLISH verpasst) |
| **5b. Email-Retries** | Max Retries: 3 ‚Üí 5 | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **Email Config:**<br>‚Ä¢ DB: `service_configs` (version=12)<br>‚Ä¢ Redis: `PUBLISH config:email:max_retries "12"` | **Append-Only History:**<br>‚Ä¢ Nie UPDATE auf History-Tabelle<br>‚Ä¢ Immer INSERT f√ºr neue √Ñnderung<br>‚Ä¢ Unver√§nderlicher Audit-Trail<br>‚Ä¢ Speichert: wer, wann, alt, neu, warum |
| **5c. Webhook-URL** | URL: `https://old.com` ‚Üí `https://new.com` | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **Webhook:**<br>‚Ä¢ DB: `service_configs` (service='webhook', key='url')<br>‚Ä¢ Redis: `PUBLISH config:webhook:url "version=X"` | **Keine Secrets in Redis:**<br>‚Ä¢ Redis tr√§gt nur Version/Event-ID<br>‚Ä¢ Keine sensiblen Daten in Pub/Sub<br>‚Ä¢ Pod l√§dt Wert aus DB (sicher) |
| **5d. Feature-Flag** | Feature "dark_mode": OFF ‚Üí ON | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **Feature:**<br>‚Ä¢ DB: `service_configs` (service='features', key='dark_mode', value='true')<br>‚Ä¢ Redis: `PUBLISH config:features:dark_mode "version=Y"` | **Multi-Pod Sync:**<br>‚Ä¢ PUBLISH ist Broadcast<br>‚Ä¢ Alle 1000 Pods empfangen gleichzeitig<br>‚Ä¢ Keine Inkonsistenzen zwischen Pods |

---

### **üîß BEREICH E: K8S-RESSOURCEN (PostgreSQL + etcd via K8s API)**
> **Was:** Infrastruktur-Limits (Storage, CPU, Memory)  
> **Wof√ºr:** Ressourcen-Management, verhindert noisy neighbor

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | ‚ö†Ô∏è GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **5i. Storage-Limit** | Quota: 10GB ‚Üí 50GB | PostgreSQL + K8s API | PostgreSQL + etcd | ~30ms | **Storage:**<br>‚Ä¢ DB: `quota_changes` (storage=50, effective_at=NOW())<br>‚Ä¢ K8s: `kubectl patch resourcequota` (storage: 50Gi) | **FinOps-Tracking:**<br>‚Ä¢ Tabelle `quota_changes` speichert Historie<br>‚Ä¢ Felder: org_id, cpu, memory, storage, effective_at, reason, actor<br>‚Ä¢ JOIN mit Prometheus f√ºr tats√§chliche Nutzung<br>‚Ä¢ Billing-System nutzt `effective_at` f√ºr Abrechnung<br><br>**Erwartung:**<br>‚Ä¢ Neue Quota gilt NUR f√ºr neue Pods<br>‚Ä¢ Laufende Pods behalten alte Limits<br>‚Ä¢ UI zeigt: "√Ñnderung aktiv nach Neustart" |
| **5j. CPU-Limit** | CPU: 10 ‚Üí 20 Cores | PostgreSQL + K8s API | PostgreSQL + etcd | ~30ms | **Compute:**<br>‚Ä¢ DB: `quota_changes` (cpu=20, effective_at=NOW())<br>‚Ä¢ K8s: `kubectl patch resourcequota` (cpu: 20) | **Abrechnung:**<br>‚Ä¢ `effective_at` = Zeitpunkt der √Ñnderung<br>‚Ä¢ Billing: "10 Cores 01.10-15.10, 20 Cores ab 16.10"<br>‚Ä¢ Prometheus-Metriken f√ºr tats√§chliche Auslastung<br>‚Ä¢ Effizienz-Report: Quota vs. Nutzung |

---

### **üî• BEREICH F: HOT-RELOAD (Redis Pub/Sub ‚Üí Pod RAM)**
> **Was:** Services empfangen Config-Updates in Echtzeit  
> **Wof√ºr:** Keine Pod-Restarts, <100ms Latenz

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | ‚ö†Ô∏è GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **6. Service empf√§ngt** | Redis SUBSCRIBE Event | Pod Memory: neuer Wert | Pod RAM | <100ms | **Mechanismus:**<br>‚Ä¢ Background-Thread: `SUBSCRIBE config:*`<br>‚Ä¢ Bei Event: Versionspr√ºfung + DB-Abfrage<br>‚Ä¢ Update: `self.config[key] = new_value`<br>‚Ä¢ Kein Restart, kein Downtime | **Redis-H√§rtung:**<br>‚Ä¢ **TLS:** Verschl√ºsselte Verbindung (rediss://)<br>‚Ä¢ **ACL:** User-basierte Zugriffsrechte, nur SUBSCRIBE erlaubt<br>‚Ä¢ **Keine Secrets:** Redis tr√§gt nur Versions-IDs<br><br>**Resilienz:**<br>‚Ä¢ Backoff + Replay bei Reconnect<br>‚Ä¢ Pod holt aktuelle Versionen aus DB nach Neustart<br>‚Ä¢ Exponentielles Backoff: 1s, 2s, 4s, 8s, max 60s<br><br>**Warm-Load:**<br>‚Ä¢ Pod startet ‚Üí l√§dt ALLE Configs aus DB<br>‚Ä¢ Dann subscribe zu Redis f√ºr Updates<br>‚Ä¢ Kein "kalter Start" mit fehlenden Configs<br><br>**Reconcile:**<br>‚Ä¢ Alle 5-10 min: DB-Version vs. lokale Version<br>‚Ä¢ Falls Drift erkannt ‚Üí Nachladen<br>‚Ä¢ Verhindert "verpasste" PUBLISH-Events |
| **7. N√§chster Request** | Nutzt neuen Wert | - | - | - | **Beispiele:**<br>‚Ä¢ AI: `if score > self.threshold` (0.90)<br>‚Ä¢ Email: `retry < self.max_retries` (5)<br>‚Ä¢ API: `if rpm > self.rate_limit` ‚Üí HTTP 429 | **Monitoring:**<br>‚Ä¢ Metric: `config_version{org_id, service, key}`<br>‚Ä¢ Alert: "Config-Version zwischen Pods unterschiedlich"<br>‚Ä¢ Dashboard: Durchschnittliche Hot-Reload-Latenz<br>‚Ä¢ Ziel: <100ms vom Backend-UPDATE bis Pod-Anwendung |

---

## üéØ Kern-Prinzipien - NACH SPEICHER-BEREICHEN

| Prinzip | Regel | Warum? | Beispiel | Anti-Pattern |
|---------|-------|--------|----------|--------------|
| **PostgreSQL = Source of Truth** | Alle Configs ‚Üí DB (immer) | Audit, Backup, Migration | ‚Ä¢ `service_configs` Tabelle<br>‚Ä¢ `config_history` (Audit-Log)<br>‚Ä¢ pg_dump = alle Configs exportiert | ‚ùå Configs nur in Redis (nicht persistent)<br>‚ùå Configs nur in etcd (kein Audit) |
| **Redis = Hot-Reload Channel** | Config-√Ñnderung ‚Üí PUBLISH | Echtzeit (<100ms), Multi-Pod Sync | ‚Ä¢ `PUBLISH config:ai:threshold "version=5"`<br>‚Ä¢ Alle AI-Pods empfangen gleichzeitig<br>‚Ä¢ Kein Polling, kein Restart | ‚ùå DB Polling alle 5s (Delay + Last)<br>‚ùå ConfigMap √§ndern ‚Üí Pod neu starten (Downtime) |
| **etcd = K8s-Ressourcen ONLY** | Nur CPU, Memory, Storage, Network | K8s-intern, nicht f√ºr Apps | ‚Ä¢ `ResourceQuota` (cpu, memory, storage)<br>‚Ä¢ `NetworkPolicy` (deny-all)<br>‚Ä¢ `RoleBinding` (RBAC) | ‚ùå App-Configs in etcd (kein Audit)<br>‚ùå User-Daten in etcd (1.5 MB Limit) |
| **Separation by Type** | **App-Config** ‚Üí PostgreSQL+Redis<br>**K8s-Ressourcen** ‚Üí PostgreSQL+etcd | Klare Trennung | ‚Ä¢ **App:** AI-Threshold, Email-Retries<br>‚Ä¢ **K8s:** CPU-Quota, Storage-Limit | ‚ùå Alles in einem System mischen |

---

## üìä Visuelle √úbersicht: Wo liegt was?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PostgreSQL (App-DB)                                        ‚îÇ
‚îÇ  ‚îú‚îÄ organizations (Tenant-Metadaten)                        ‚îÇ
‚îÇ  ‚îú‚îÄ projects (Business-Daten)                               ‚îÇ
‚îÇ  ‚îú‚îÄ notes (User-Daten)                                      ‚îÇ
‚îÇ  ‚îú‚îÄ service_configs (App-Configs + K8s-Ressourcen-Mirror)  ‚îÇ
‚îÇ  ‚îú‚îÄ config_history (Audit-Log: wer, wann, was)             ‚îÇ
‚îÇ  ‚îî‚îÄ quota_changes (FinOps: CPU/Memory/Storage Historie)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì (speichert + notifiziert)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Redis (Hot-Reload Channel)                                 ‚îÇ
‚îÇ  ‚îú‚îÄ Channels: config:ai:*, config:email:*, config:api:*    ‚îÇ
‚îÇ  ‚îú‚îÄ TLS verschl√ºsselt (rediss://)                          ‚îÇ
‚îÇ  ‚îî‚îÄ ACL: nur SUBSCRIBE erlaubt, keine Secrets              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì (SUBSCRIBE)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Pod RAM (Service Memory)                                   ‚îÇ
‚îÇ  ‚îú‚îÄ self.threshold = 0.90  (Hot-Reload <100ms)             ‚îÇ
‚îÇ  ‚îú‚îÄ Warm-Load beim Start (alle Configs aus DB)             ‚îÇ
‚îÇ  ‚îî‚îÄ Reconcile alle 5-10 min (falls PUBLISH verpasst)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  etcd (K8s Control Plane)                                   ‚îÇ
‚îÇ  ‚îú‚îÄ /registry/namespaces/org-acme                          ‚îÇ
‚îÇ  ‚îú‚îÄ /registry/resourcequotas/org-acme (CPU, Memory, Storage)‚îÇ
‚îÇ  ‚îú‚îÄ /registry/networkpolicies/org-acme (deny-all)          ‚îÇ
‚îÇ  ‚îî‚îÄ /registry/rbac/rolebindings/org-acme (admin)           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ MINI-CHECKLIST (Sofort nutzbar)

| # | Guardrail | Beschreibung | Wo implementieren? |
|---|-----------|--------------|-------------------|
| **1** | **Idempotenz & SAGA** | Operation-ID in DB + K8s-Annotation, Status `PENDING/COMMITTED/FAILED`, kompensierende L√∂schung bei Fehler | Backend API |
| **2** | **Namespace-Gate** | Kyverno/OPA Policy blockt Pods bis Label `isolation-ready=true` gesetzt ist | Cluster-Policy |
| **3** | **RLS aktiv** | Row-Level Security auf PostgreSQL-Ebene, automatische Tenant-Isolation | PostgreSQL |
| **4** | **Config-Versionierung** | Monotone Version-Nummer, Pub/Sub tr√§gt nur org_id + key + version (kein Value) | DB Schema + Backend |
| **5** | **Redis-H√§rtung** | TLS verschl√ºsselt, ACL-basierte Zugriffsrechte, keine Secrets in Topics, Warm-Load + Reconcile | Redis Config + Deployment |
| **6** | **FinOps-Tabellen** | `quota_changes` Tabelle mit effective_at, JOIN mit Prometheus-Metriken f√ºr Kosten-Reports | PostgreSQL + Prometheus |
| **7** | **JTI-Denylist** | JWT-ID in Denylist f√ºr Sofort-Widerruf bei Token-Compromise | Redis/PostgreSQL |
| **8** | **PITR-Runbook** | WAL-Archiving aktiv, dokumentierter Restore-Prozess mit 5-Minuten-RPO | PostgreSQL Config + Doku |
| **9** | **Reconcile-Loop** | Alle 5-10 min: Pr√ºfe DB-Version vs. lokale Config-Version, lade nach bei Drift | Pod Background-Thread |
| **10** | **FinOps-Transparenz** | UI zeigt "Neue Quota gilt ab Restart", `effective_at` Timestamp f√ºr Abrechnungs-Genauigkeit | UI + Billing-System |

---

## üìö Dokumentation

- **[Architecture Guide](/docs/architecture/ARCHITECTURE.md)** - Enterprise-Grade Referenz-Architektur (10/10 Qualit√§t)
- **[Quickstart](/docs/quickstart/Quickstart.md)** - Setup-Guide und Troubleshooting
- **[Roadmap](/ROADMAP.md)** - Phasen-Checklisten und Fortschritt

---

## üöÄ Quick Start

```bash
# Phase 1: Lokale Entwicklung (kind cluster)
./setup-template/setup-phase1.sh

# Status pr√ºfen
kubectl get pods -A
kind get clusters
```

---

## üõ†Ô∏è Tech Stack

### **Kern-Infrastruktur**
- **Kubernetes:** kind (lokal), AKS/EKS/GKE (Cloud)
- **GitOps:** Argo CD, Kustomize
- **Datenbank:** PostgreSQL (StatefulSet)
- **Cache:** Redis (Hot-Reload Config, Pub/Sub)
- **Secrets:** External Secrets Operator ‚Üí Azure Key Vault/AWS Secrets Manager/HashiCorp Vault

### **Sicherheit**
- **Image Signing:** Cosign (keyless OIDC/KMS/Vault)
- **Policy Engine:** Kyverno/OPA Gatekeeper
- **Network:** NetworkPolicies (deny-all baseline)
- **RBAC:** Multi-Tenant-Isolation pro Namespace

### **Observability**
- **Metriken:** kube-prometheus-stack (Prometheus + Grafana)
- **Logs:** Loki
- **Traces:** Tempo/OpenTelemetry Collector
- **Dashboards:** SLO Burn Rate, Certificate Expiry, External Probe Health

---

## üéØ Use Cases

‚úÖ **Multi-Tenant SaaS-Plattformen** (wie Azure DevOps, GitLab, Shopify)  
‚úÖ **AI/ML-Plattformen** mit Hot-Reload Model-Configs  
‚úÖ **Developer-Plattformen** mit Self-Service Projekt-Erstellung  
‚úÖ **Enterprise-Grade Infrastruktur** (ISO 27001, NIS2, SOC 2 ready)

---

## üìÑ Lizenz

MIT License - siehe [LICENSE](LICENSE)

---

## ü§ù Contributing

Dies ist ein AI-agent-freundliches Template. Alle Code, Docs und Commits m√ºssen in **Englisch** sein.

**Update [`.github/copilot-instructions.md`](.github/copilot-instructions.md)** bei strukturellen √Ñnderungen!

---

## üîß FAQ: Technologie-Entscheidungen

### **Warum KubernetesClient statt dotnet-etcd?**

| Aspekt | `dotnet-etcd` | `KubernetesClient` |
|--------|---------------|-------------------|
| **Was es macht** | Spricht direkt mit etcd | Spricht mit Kubernetes API |
| **Komplexit√§t** | ‚ùå Sehr low-level, etcd-Keys selbst bauen | ‚úÖ High-level, `CreateNamespace()` fertig |
| **Sicherheit** | ‚ùå Direkter etcd-Zugriff = Risiko | ‚úÖ K8s RBAC pr√ºft Permissions |
| **Portabilit√§t** | ‚ùå Nur wenn etcd direkt erreichbar | ‚úÖ Funktioniert mit jedem K8s (AKS, EKS, GKE) |
| **Maintenance** | ‚ùå etcd-Struktur kann sich √§ndern | ‚úÖ K8s API ist stabil (Backward-Kompatibilit√§t) |

**Empfehlung:** Nutze `KubernetesClient` (oder √Ñquivalent in deiner Sprache) f√ºr 99% der F√§lle.

---

### **Ist KubernetesClient mit jeder Anwendung kompatibel?**

**KURZ: JA! Jede Sprache hat einen K8s Client.**

| Sprache | K8s Client Library | NuGet/npm/pip Package |
|---------|-------------------|-----------------------|
| **C# / .NET** | `KubernetesClient` | `KubernetesClient` |
| **Python** | `kubernetes` | `kubernetes` |
| **Node.js / JavaScript** | `@kubernetes/client-node` | `@kubernetes/client-node` |
| **Go** | `client-go` | `k8s.io/client-go` |
| **Java** | Kubernetes Java Client | `io.kubernetes:client-java` |
| **Rust** | `kube-rs` | `kube` |

**Funktioniert mit ALLEN K8s-Anbietern:**
- ‚úÖ kind (lokal)
- ‚úÖ minikube (lokal)
- ‚úÖ Azure AKS
- ‚úÖ AWS EKS
- ‚úÖ Google GKE
- ‚úÖ On-Prem kubeadm/RKE2
- ‚úÖ OpenShift

**Warum?** Kubernetes API ist standardisiert (k8s.io/api) ‚Üí funktioniert √ºberall gleich.

---

### **Warum nicht NUR etcd (ohne PostgreSQL)?**

**5 Gr√ºnde gegen "nur etcd":**

**1. Kein SQL = Entwickler-H√∂lle**
- PostgreSQL: `SELECT * FROM notes WHERE project_id = 5` ‚Üí fertig
- etcd: Alle 1000+ Keys laden, in Code filtern, sortieren ‚Üí 100x mehr Code

**2. Compliance unm√∂glich**
- PostgreSQL: `SELECT * FROM config_history WHERE changed_at >= '2025-10-01'` ‚Üí Excel-Export
- etcd: Kein `WHERE`, kein `GROUP BY` ‚Üí manuelles Filtern

**3. Backup = Alles oder Nichts**
- PostgreSQL: `pg_restore --schema=org_acme` ‚Üí Nur diese Org
- etcd: Restore = **gesamter Cluster** ‚Üí alle Tenants betroffen

**4. etcd ist klein gedacht**
- **1.5 MB pro Key** ‚Üí Gro√üe Dokumente unm√∂glich
- **8 GB gesamte DB empfohlen** ‚Üí Bei 1000 Tenants = 8 MB pro Tenant
- PostgreSQL: TB-gro√üe Datenbanken problemlos

**5. Entwickler-√ñkosystem fehlt**
- PostgreSQL: ORMs, Admin-UIs, Migrations, Cloud-Managed Services
- etcd: Roh-API, kein ORM, keine Tools

---

### **Warum PostgreSQL + etcd + Redis? (Warum nicht nur eines?)**

**Jedes System f√ºr seinen Zweck:**

| System | Wof√ºr? | Warum? | Beispiel |
|--------|--------|--------|----------|
| **etcd** | K8s-Objekte (Namespace, Quotas) | K8s liest NUR aus etcd (Millisekunden) | Namespace erstellen |
| **PostgreSQL** | App-Daten + Audit | SQL-Queries, Backup pro Tenant, Compliance | User, Projekte, Notizen, Config-History |
| **Redis** | Hot-Reload Notifications | Pub/Sub f√ºr Echtzeit-Updates (<100ms) | AI-Threshold √§ndern ‚Üí Pods sofort updaten |

**Warum nicht nur etcd?**
- ‚ùå Kein SQL (keine komplexen Queries)
- ‚ùå Kein granulares Backup (nur ganzer Cluster)
- ‚ùå Nicht f√ºr App-Daten designed (1.5 MB Limit)

**Warum nicht nur PostgreSQL?**
- ‚ùå K8s kennt kein SQL (etcd ist K8s-intern)
- ‚ùå Keine Echtzeit-Push-Notifications (Redis Pub/Sub schneller)

**Warum nicht nur Redis?**
- ‚ùå Nicht persistent genug (bei Crash = Daten weg)
- ‚ùå Kein Audit-Log (wer √§nderte wann?)

---

### **Wie erstelle ich einen neuen Tenant auf laufender Plattform?**

**User-Perspektive:**
1. Frontend: `https://platform.example.com/register`
2. Formular: "ACME Corp", "admin@acme.com", Passwort
3. Button: "Create Organization"

**Backend (120ms):**

| Schritt | Was passiert | Technologie |
|---------|-------------|-------------|
| **1. API Call** | `POST /api/organizations` | Frontend ‚Üí Backend |
| **2. DB Insert** | `INSERT INTO organizations (status='PENDING')` | PostgreSQL |
| **3. Namespace** | `kubectl create namespace org-acme` | KubernetesClient ‚Üí etcd |
| **4. Quotas** | `kubectl create resourcequota` (CPU=10, Memory=20Gi) | KubernetesClient ‚Üí etcd |
| **5. Network** | `kubectl create networkpolicy` (deny-all) | KubernetesClient ‚Üí etcd |
| **6. RBAC** | `kubectl create rolebinding` (owner=admin) | KubernetesClient ‚Üí etcd |
| **7. Gate** | `kubectl label namespace isolation-ready=true` | KubernetesClient ‚Üí etcd |
| **8. Commit** | `UPDATE organizations SET status='COMMITTED'` | PostgreSQL |

**Ergebnis:** Isolierter Namespace, ready in ~120ms! ‚úÖ

**Wo in README?** ‚Üí Tabelle 6, Bereich A (Zeilen 1a-1d)

---

### **Warum PostgreSQL + Redis f√ºr Configs (nicht nur eines)?**

**PostgreSQL = Source of Truth (Persistent):**
- Config-√Ñnderung wird **immer** in DB gespeichert
- Audit-Log: Wer √§nderte wann was warum?
- Backup/Restore: Bei Disaster ‚Üí DB restore ‚Üí alle Configs zur√ºck

**Redis = Hot-Reload Channel (Real-Time):**
- PostgreSQL hat **kein Push-Notification-System**
- Ohne Redis: Pods m√ºssten DB pollen (alle 5s) ‚Üí DB-Last + Delay
- Mit Redis: `PUBLISH config:ai:threshold "version=5"` ‚Üí alle Pods sofort (<100ms)

**Warum beide?**
- Nur PostgreSQL = Polling-Delay (0-5s), DB-Last
- Nur Redis = Nicht persistent (Crash = Config weg), kein Audit
- **Beide = Best-of-Both-Worlds** ‚úÖ

---

### **Macht Microsoft das auch so?**

**JA, sehr √§hnlich!**

| Feature | Dein System | Azure/Microsoft |
|---------|-------------|-----------------|
| **Tenant-Erstellung** | PostgreSQL (Metadata) + etcd (Namespace) | Azure SQL + ARM/Fabric Controller |
| **Hot-Reload Config** | PostgreSQL + Redis Pub/Sub | Azure App Config + Event Grid |
| **Auth** | JWT (1h TTL) | Azure AD Access Token (1h TTL) |
| **Backup** | pg_dump pro Tenant | Azure SQL per-database backup |
| **Audit** | config_history Tabelle | Azure Activity Log |

**Unterschied:**
- Azure: Event Grid (HTTP Webhooks) statt Redis Pub/Sub
- Unser System: Einfacher, keine Firewall-Config n√∂tig, Open Source

**Fazit:** Konzeptionell identisch, nur andere Namen f√ºr gleiche Patterns! ‚úÖ

---

### **Gilt das auch f√ºr lokal (kind/minikube)?**

**JA, exakt das gleiche!**

| Komponente | Lokal (kind) | Cloud (AKS/EKS/GKE) | Unterschied? |
|------------|--------------|---------------------|--------------|
| **KubernetesClient** | ‚úÖ Funktioniert | ‚úÖ Funktioniert | ‚ùå KEIN Unterschied |
| **PostgreSQL** | ‚úÖ StatefulSet im Cluster | ‚úÖ Azure Database / RDS | ‚ö†Ô∏è Nur Hosting, API gleich |
| **Redis** | ‚úÖ Deployment im Cluster | ‚úÖ Azure Cache / ElastiCache | ‚ö†Ô∏è Nur Hosting, Pub/Sub gleich |
| **etcd** | ‚úÖ In kind eingebaut | ‚úÖ Managed (AKS/EKS) | ‚ùå KEIN Unterschied (transparent) |
| **Tenant-Erstellung** | ‚úÖ 120ms | ‚úÖ 120ms | ‚ùå KEIN Unterschied |
| **Hot-Reload** | ‚úÖ <100ms | ‚úÖ <100ms | ‚ùå KEIN Unterschied |

**Was ist identisch?**
- ‚úÖ Namespace erstellen: `kubectl create namespace` (gleich)
- ‚úÖ PostgreSQL: SQL-Queries (gleich)
- ‚úÖ Redis Pub/Sub: Channels (gleich)
- ‚úÖ KubernetesClient Code: Keine √Ñnderung n√∂tig (gleich)

**Einziger Unterschied:**
- Lokal: PostgreSQL + Redis im Cluster deployen (Helm Charts)
- Cloud: PostgreSQL + Redis als Managed Service nutzen (Azure Database, Azure Cache)

**Vorteil:** Entwickeln auf kind ‚Üí Deployen auf AKS ‚Üí **Zero Code Changes!** üöÄ

---

### **Was muss die App mitbringen f√ºr Tenant-Erstellung?**

**4 Komponenten:**

#### **1. Backend API mit Kubernetes-Zugriff**

**Braucht:**
- ‚úÖ Kubernetes Client Library (KubernetesClient f√ºr C#, kubernetes f√ºr Python, @kubernetes/client-node f√ºr Node.js)
- ‚úÖ ServiceAccount mit RBAC-Permissions (darf Namespaces, ResourceQuotas, NetworkPolicies erstellen)

#### **2. Datenbank-Verbindung (PostgreSQL)**

**Braucht:**
- ‚úÖ PostgreSQL-Instanz (im Cluster oder Managed Service)
- ‚úÖ 4 Tabellen:
  - `organizations` (id, name, owner_email, status, operation_id)
  - `service_configs` (org_id, service, key, value, version)
  - `config_history` (config_id, old_value, new_value, changed_by, changed_at)
  - `quota_changes` (org_id, cpu, memory, storage, effective_at)

#### **3. Redis-Verbindung (f√ºr Hot-Reload)**

**Braucht:**
- ‚úÖ Redis-Instanz (im Cluster oder Managed Service)
- ‚úÖ Pub/Sub Support (Standard-Feature)
- ‚ö†Ô∏è Optional f√ºr Production: TLS + ACL

#### **4. Frontend (UI f√ºr User)**

**Braucht:**
- ‚úÖ Registrierungs-Formular (Org Name, Owner Email, Passwort)
- ‚úÖ API-Call: `POST /api/organizations`

---

### **Minimal-Setup √úbersicht**

| Komponente | Was installieren? | Konfiguration |
|------------|-------------------|---------------|
| **Backend** | FastAPI/Node.js/ASP.NET + KubernetesClient | ServiceAccount + RBAC ClusterRole |
| **PostgreSQL** | Helm: `bitnami/postgresql` | 4 Tabellen (organizations, service_configs, config_history, quota_changes) |
| **Redis** | Helm: `bitnami/redis` | Standard-Config (kein TLS f√ºr lokal) |
| **Frontend** | React/Vue/Angular App | Registrierungs-Formular + API-Integration |

---

### **Backend RBAC-Permissions (ben√∂tigt)**

Backend ServiceAccount braucht folgende Kubernetes-Rechte:

| Ressource | Verben | Warum? |
|-----------|--------|--------|
| **namespaces** | create, get, list, patch, delete | Tenant-Namespaces verwalten |
| **resourcequotas** | create, get, list, patch | CPU/Memory/Storage-Limits setzen |
| **networkpolicies** | create, get, list | Netzwerk-Isolation (deny-all baseline) |
| **rolebindings** | create, get, list | Owner ‚Üí Admin-Rolle im Namespace |

---

### **Checkliste: Bereit f√ºr Tenant-Erstellung?**

- [ ] Backend mit KubernetesClient installiert
- [ ] Backend hat ServiceAccount + RBAC Permissions
- [ ] PostgreSQL l√§uft (im Cluster oder extern)
- [ ] PostgreSQL hat 4 Tabellen erstellt
- [ ] Redis l√§uft (im Cluster oder extern)
- [ ] Frontend kann `POST /api/organizations` aufrufen
- [ ] Test: Backend kann Namespaces erstellen (`kubectl auth can-i create namespace`)

**Alles ‚úÖ? Dann bereit f√ºr ersten Tenant!** üöÄ
