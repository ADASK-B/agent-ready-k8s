# agent-ready-k8s

> **AI-gesteuerte Kubernetes-Plattform-Vorlage**  
> Multi-Tenant SaaS-Plattform mit Self-Service Tenant-Erstellung, Hot-Reload-Konfiguration und Enterprise-Grade-Architektur.

---

## ğŸ“Š Architektur-Ãœbersicht

### **Tabelle 1: Datenspeicherung - Wo liegt was?**

| Datentyp | Speicherort | Beispiel | Warum hier? | Warum NICHT woanders? |
|----------|-------------|----------|-------------|-----------------------|
| **Tenant-Metadaten** | PostgreSQL (App-DB) | `org_name="ACME Corp"`, `owner_email` | âœ… Flexible Queries (JOIN, Filter)<br>âœ… Backup/Migration einfach<br>âœ… UnabhÃ¤ngig von K8s | âŒ etcd = kein SQL, K8s-intern<br>âŒ Verlust bei Cluster-Migration |
| **K8s-Konfiguration** | etcd (K8s interne DB) | Namespace, RBAC, Quotas | âœ… K8s liest/schreibt direkt<br>âœ… Millisekunden-Latenz<br>âœ… Distributed Consensus (HA) | âŒ PostgreSQL = zu langsam fÃ¼r K8s<br>âŒ Keine Strong Consistency |
| **User-Daten (Notizen)** | PostgreSQL (im Pod im Namespace) | `note_id=123`, `content="Meeting Notes"` | âœ… ACID-Transaktionen<br>âœ… Komplexe Queries<br>âœ… BewÃ¤hrte Backups (pg_dump) | âŒ etcd = Max 1.5 MB pro Key<br>âŒ Nicht fÃ¼r App-Daten designed |
| **Secrets (PasswÃ¶rter)** | etcd (verschlÃ¼sselt) ODER Azure Key Vault | DB-Passwort, API-Keys | âœ… K8s-native Injection (envFrom)<br>âœ… Rotation via ESO<br>âœ… Hardware-backed (HSM) | âŒ PostgreSQL = Sicherheitsrisiko<br>âŒ Git = NIEMALS Secrets committen |

---

### **Tabelle 2: Tenant-Erstellung (Self-Service wie Azure)**

| Schritt | Aktion | Wo gespeichert? | Wer macht es? | Latenz |
|---------|--------|-----------------|---------------|--------|
| **1. User registriert sich** | User klickt "Create Organization" | Browser â†’ Backend API | User | - |
| **2. Metadaten speichern** | `INSERT INTO organizations (name, owner)` | PostgreSQL | Backend API | ~10ms |
| **3. Namespace erstellen** | `kubectl create namespace org-acme` | etcd (via K8s API) | Backend â†’ K8s API | ~50ms |
| **4. RBAC erstellen** | `kubectl create rolebinding admin` | etcd | Backend â†’ K8s API | ~20ms |
| **5. ResourceQuota** | CPU=10, Memory=20Gi | etcd | Backend â†’ K8s API | ~20ms |
| **6. NetworkPolicy** | Deny-all Baseline | etcd | Backend â†’ K8s API | ~20ms |

**Gesamt:** ~120ms = **Self-Service wie Azure** âœ…

---

### **Tabelle 3: Hot-Reload Config (AI-Threshold Beispiel)**

| Option | Wo gespeichert? | Hot-Reload? | Latenz | Warum nutzen? | Warum NICHT nutzen? |
|--------|-----------------|-------------|--------|---------------|---------------------|
| **PostgreSQL (Polling)** | `settings` Tabelle | âš ï¸ JA (5s VerzÃ¶gerung) | 0-5s | âœ… Einfach, keine Extra-Dependencies | âŒ DB-Last, nicht Echtzeit |
| **Redis Pub/Sub** | Redis Key + PUBLISH | âœ… JA | <100ms | âœ… Echtzeit<br>âœ… Multi-Pod Sync | âš ï¸ Extra Dependency |
| **ConfigMap + Reloader** | K8s ConfigMap | âš ï¸ JA (Restart) | ~15s | âœ… K8s-native, GitOps | âŒ Pod-Restart = Downtime |
| **etcd (direkt)** | etcd Key + Watch API | âœ… JA | <50ms | âœ… K8s-intern vorhanden | âŒ Komplex, Sicherheitsrisiko<br>âŒ Nicht fÃ¼r Apps designed |

**Empfehlung:** PostgreSQL (Source of Truth) + Redis (Hot-Reload) âœ…

---

### **Tabelle 4: Warum NICHT etcd fÃ¼r App-Config?**

| Problem | Konsequenz | Alternative |
|---------|------------|-------------|
| Nicht fÃ¼r App-Daten designed | etcd = K8s Control Plane Storage | PostgreSQL fÃ¼r App-Daten |
| Komplexe RBAC | Pod braucht K8s API-Zugriff = Sicherheitsrisiko | Redis = App-Level, kein K8s-Zugriff nÃ¶tig |
| Keine native Watch-API fÃ¼r Apps | 50+ Zeilen Boilerplate-Code | Redis Pub/Sub = 5 Zeilen Code |
| Backup/Audit schwierig | etcd-Backup = gesamter Cluster (GB) | PostgreSQL-Backup = nur deine Daten (MB) |
| Skalierungs-Limit | Max 8 GB empfohlen | PostgreSQL+Redis = TB-fÃ¤hig |
| Vendor Lock-In | K8s-spezifisch | PostgreSQL+Redis = Ã¼berall nutzbar |

---

### **Tabelle 5: Dein System vs. Azure DevOps**

| Feature | Dein K8s-System | Azure DevOps | Vorteil |
|---------|-----------------|--------------|---------|
| **Multi-Tenancy** | Namespace pro Org | Azure Org/Projects | âœ… Gleich (beide Self-Service) |
| **Tenant-Erstellung** | API â†’ K8s Operator | Azure Portal â†’ ARM | âœ… Gleich (~100ms) |
| **Hot-Reload Config** | PostgreSQL + Redis Pub/Sub | Azure App Configuration + Event Grid | âœ… Dein System schneller (<100ms vs. ~500ms) |
| **Feature Flags** | Custom (Redis/DB) | Native (Azure App Config) | âš ï¸ Azure besser (Out-of-Box) |
| **Kosten** | $0 (self-hosted) | $1-10/Monat (managed) | âœ… Dein System gÃ¼nstiger |
| **Vendor Lock-In** | âŒ NEIN (Open Source) | âœ… JA (Azure-only) | âœ… Dein System portabel |
| **Secrets Management** | ESO â†’ Key Vault/Vault | Azure Key Vault (native) | âœ… Gleich |

---

## ğŸ“Š Tabelle 6: Workflow-Ãœbersicht (End-to-End) - NACH SPEICHER-BEREICHEN

---

### **ğŸ—„ï¸ BEREICH A: TENANT & INFRASTRUKTUR (PostgreSQL + etcd)**
> **Was:** Org-Erstellung, K8s-Ressourcen (Namespace, Quotas, Network)  
> **WofÃ¼r:** Grundlegende Tenant-Isolation und Ressourcen-Limits

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | âš ï¸ GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **1a. Registrierung** | "Create Org: ACME Corp" | Backend â†’ PostgreSQL + K8s API | PostgreSQL + etcd | ~120ms | **Org-Erstellung:**<br>â€¢ DB: `organizations` (id, name, owner_email)<br>â€¢ K8s: Namespace `org-acme` | **SAGA-Pattern:**<br>â€¢ Status: `PENDING` â†’ K8s create â†’ `COMMITTED`<br>â€¢ Bei Fehler: `FAILED` + kompensierende LÃ¶schung<br><br>**Idempotenz:**<br>â€¢ Operation-ID in DB + K8s-Annotation<br>â€¢ Verhindert doppelte Org bei Retry |
| **1b. Initial Storage** | System setzt Default: 10GB | Backend â†’ K8s API | etcd + PostgreSQL | ~20ms | **Storage Init:**<br>â€¢ K8s: `ResourceQuota` (storage: 10Gi)<br>â€¢ DB: `service_configs` (Audit-Log) | **Namespace-Gate:**<br>â€¢ Policy blockt Pods bis Label `isolation-ready=true` gesetzt<br>â€¢ Verhindert Race-Conditions |
| **1c. Initial CPU/Memory** | System setzt Default: CPU=10, Memory=20Gi | Backend â†’ K8s API | etcd + PostgreSQL | ~20ms | **Compute Init:**<br>â€¢ K8s: `ResourceQuota` (cpu: 10, memory: 20Gi)<br>â€¢ DB: `service_configs` (Audit-Log) | **Race-free Isolation:**<br>â€¢ Onboarding-Job setzt `isolation-ready=true` NACH:<br>&nbsp;&nbsp;1. Default-Deny NetworkPolicy<br>&nbsp;&nbsp;2. ResourceQuotas<br>&nbsp;&nbsp;3. RBAC |
| **1d. NetworkPolicy** | System aktiviert Isolation | Backend â†’ K8s API | etcd | ~20ms | **Network Init:**<br>â€¢ K8s: `NetworkPolicy` (deny-all baseline) | **Cluster-Policy-Gate:**<br>â€¢ Kyverno/OPA Policy enforced:<br>â€¢ Pods in neuen Namespaces = `Pending` bis `isolation-ready=true` |

---

### **ğŸ” BEREICH B: AUTHENTIFIZIERUNG (JWT Token)**
> **Was:** User-Login, Token-Generierung  
> **WofÃ¼r:** Zugriffskontrolle, Session-Management

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | âš ï¸ GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **2. Login** | Email + Passwort | JWT Token via OAuth2-Proxy | - (ephemeral) | ~50ms | **Auth:**<br>â€¢ Token: `org_id=123`, `user_role=admin`, `permissions=[...]` | **Sofort-Widerruf:**<br>â€¢ **Option A:** Key-Rotation (kurze TTL + Signier-Keywechsel)<br>â€¢ **Option B:** JTI-Denylist (Redis/DB) fÃ¼r NotfÃ¤lle<br><br>**TTL-Strategie:**<br>â€¢ Access-Token: 1h (wie Azure AD)<br>â€¢ Refresh-Token: 90d (sliding window)<br><br>**Security:**<br>â€¢ Token enthÃ¤lt `jti` (JWT ID) fÃ¼r Tracking<br>â€¢ Bei Compromise: `jti` in Denylist â†’ Token ungÃ¼ltig |

---

### **ğŸ“¦ BEREICH C: BUSINESS-DATEN (PostgreSQL)**
> **Was:** User-Daten (Projekte, Notizen, Dokumente)  
> **WofÃ¼r:** Eigentliche App-FunktionalitÃ¤t

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | âš ï¸ GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **3. Projekt erstellen** | "Create Project: Notes App" | Backend â†’ PostgreSQL | PostgreSQL | ~10ms | **Project:**<br>â€¢ Tabelle: `projects` (id, name, org_id) | **Row-Level Security (RLS):**<br>â€¢ PostgreSQL-Feature aktiviert<br>â€¢ Automatische Filter nach `org_id`<br>â€¢ Backend setzt: `SET app.current_org = 123`<br><br>**Policy:**<br>â€¢ Tenant-Isolation auf DB-Ebene<br>â€¢ Queries sehen nur eigene Org-Daten |
| **4. Notiz schreiben** | "Meeting with customer" | Backend â†’ PostgreSQL | PostgreSQL | ~10ms | **Data:**<br>â€¢ Tabelle: `notes` (id, project_id, content) | **RLS + PITR:**<br>â€¢ **RLS:** Automatische Filter nach `org_id`<br>â€¢ **PITR:** WAL-Archiving aktiv<br>â€¢ **Restore-Runbook:** 5-Minuten-RPO<br>â€¢ **Backup:** pg_dump tÃ¤glich + WAL kontinuierlich |

---

### **âš™ï¸ BEREICH D: SERVICE-CONFIGS (PostgreSQL + Redis Hot-Reload)**
> **Was:** App-Einstellungen (AI-Threshold, Email-Retries, Webhooks, Feature-Flags)  
> **WofÃ¼r:** Hot-Reload Config ohne Pod-Restart

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | âš ï¸ GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **5a. AI-Threshold** | Slider: 0.75 â†’ 0.90 | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **AI Config:**<br>â€¢ DB: `service_configs` (service='ai', key='threshold', value='0.90', version=5)<br>â€¢ Redis: `PUBLISH config:ai:threshold "version=5"`<br>â€¢ Audit: `config_history` | **Versionierung:**<br>â€¢ Monoton steigende Version-Nummer<br>â€¢ Pub/Sub trÃ¤gt nur Version (kein Value)<br>â€¢ Pod holt Value aus DB bei Version-ErhÃ¶hung<br><br>**Resilienz:**<br>â€¢ Warm-Load beim Start (alle Configs aus DB)<br>â€¢ Reconcile alle 5-10 min (falls PUBLISH verpasst) |
| **5b. Email-Retries** | Max Retries: 3 â†’ 5 | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **Email Config:**<br>â€¢ DB: `service_configs` (version=12)<br>â€¢ Redis: `PUBLISH config:email:max_retries "12"` | **Append-Only History:**<br>â€¢ Nie UPDATE auf History-Tabelle<br>â€¢ Immer INSERT fÃ¼r neue Ã„nderung<br>â€¢ UnverÃ¤nderlicher Audit-Trail<br>â€¢ Speichert: wer, wann, alt, neu, warum |
| **5c. Webhook-URL** | URL: `https://old.com` â†’ `https://new.com` | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **Webhook:**<br>â€¢ DB: `service_configs` (service='webhook', key='url')<br>â€¢ Redis: `PUBLISH config:webhook:url "version=X"` | **Keine Secrets in Redis:**<br>â€¢ Redis trÃ¤gt nur Version/Event-ID<br>â€¢ Keine sensiblen Daten in Pub/Sub<br>â€¢ Pod lÃ¤dt Wert aus DB (sicher) |
| **5d. Feature-Flag** | Feature "dark_mode": OFF â†’ ON | PostgreSQL + Redis PUBLISH | PostgreSQL + Redis | ~15ms | **Feature:**<br>â€¢ DB: `service_configs` (service='features', key='dark_mode', value='true')<br>â€¢ Redis: `PUBLISH config:features:dark_mode "version=Y"` | **Multi-Pod Sync:**<br>â€¢ PUBLISH ist Broadcast<br>â€¢ Alle 1000 Pods empfangen gleichzeitig<br>â€¢ Keine Inkonsistenzen zwischen Pods |

---

### **ğŸ”§ BEREICH E: K8S-RESSOURCEN (PostgreSQL + etcd via K8s API)**
> **Was:** Infrastruktur-Limits (Storage, CPU, Memory)  
> **WofÃ¼r:** Ressourcen-Management, verhindert noisy neighbor

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | âš ï¸ GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **5i. Storage-Limit** | Quota: 10GB â†’ 50GB | PostgreSQL + K8s API | PostgreSQL + etcd | ~30ms | **Storage:**<br>â€¢ DB: `quota_changes` (storage=50, effective_at=NOW())<br>â€¢ K8s: `kubectl patch resourcequota` (storage: 50Gi) | **FinOps-Tracking:**<br>â€¢ Tabelle `quota_changes` speichert Historie<br>â€¢ Felder: org_id, cpu, memory, storage, effective_at, reason, actor<br>â€¢ JOIN mit Prometheus fÃ¼r tatsÃ¤chliche Nutzung<br>â€¢ Billing-System nutzt `effective_at` fÃ¼r Abrechnung<br><br>**Erwartung:**<br>â€¢ Neue Quota gilt NUR fÃ¼r neue Pods<br>â€¢ Laufende Pods behalten alte Limits<br>â€¢ UI zeigt: "Ã„nderung aktiv nach Neustart" |
| **5j. CPU-Limit** | CPU: 10 â†’ 20 Cores | PostgreSQL + K8s API | PostgreSQL + etcd | ~30ms | **Compute:**<br>â€¢ DB: `quota_changes` (cpu=20, effective_at=NOW())<br>â€¢ K8s: `kubectl patch resourcequota` (cpu: 20) | **Abrechnung:**<br>â€¢ `effective_at` = Zeitpunkt der Ã„nderung<br>â€¢ Billing: "10 Cores 01.10-15.10, 20 Cores ab 16.10"<br>â€¢ Prometheus-Metriken fÃ¼r tatsÃ¤chliche Auslastung<br>â€¢ Effizienz-Report: Quota vs. Nutzung |

---

### **ğŸ”¥ BEREICH F: HOT-RELOAD (Redis Pub/Sub â†’ Pod RAM)**
> **Was:** Services empfangen Config-Updates in Echtzeit  
> **WofÃ¼r:** Keine Pod-Restarts, <100ms Latenz

| Schritt | User-Aktion | System-Reaktion | Wo gespeichert? | Latenz | Beispiel/Details | âš ï¸ GUARDRAILS |
|---------|-------------|-----------------|-----------------|--------|------------------|----------------|
| **6. Service empfÃ¤ngt** | Redis SUBSCRIBE Event | Pod Memory: neuer Wert | Pod RAM | <100ms | **Mechanismus:**<br>â€¢ Background-Thread: `SUBSCRIBE config:*`<br>â€¢ Bei Event: VersionsprÃ¼fung + DB-Abfrage<br>â€¢ Update: `self.config[key] = new_value`<br>â€¢ Kein Restart, kein Downtime | **Redis-HÃ¤rtung:**<br>â€¢ **TLS:** VerschlÃ¼sselte Verbindung (rediss://)<br>â€¢ **ACL:** User-basierte Zugriffsrechte, nur SUBSCRIBE erlaubt<br>â€¢ **Keine Secrets:** Redis trÃ¤gt nur Versions-IDs<br><br>**Resilienz:**<br>â€¢ Backoff + Replay bei Reconnect<br>â€¢ Pod holt aktuelle Versionen aus DB nach Neustart<br>â€¢ Exponentielles Backoff: 1s, 2s, 4s, 8s, max 60s<br><br>**Warm-Load:**<br>â€¢ Pod startet â†’ lÃ¤dt ALLE Configs aus DB<br>â€¢ Dann subscribe zu Redis fÃ¼r Updates<br>â€¢ Kein "kalter Start" mit fehlenden Configs<br><br>**Reconcile:**<br>â€¢ Alle 5-10 min: DB-Version vs. lokale Version<br>â€¢ Falls Drift erkannt â†’ Nachladen<br>â€¢ Verhindert "verpasste" PUBLISH-Events |
| **7. NÃ¤chster Request** | Nutzt neuen Wert | - | - | - | **Beispiele:**<br>â€¢ AI: `if score > self.threshold` (0.90)<br>â€¢ Email: `retry < self.max_retries` (5)<br>â€¢ API: `if rpm > self.rate_limit` â†’ HTTP 429 | **Monitoring:**<br>â€¢ Metric: `config_version{org_id, service, key}`<br>â€¢ Alert: "Config-Version zwischen Pods unterschiedlich"<br>â€¢ Dashboard: Durchschnittliche Hot-Reload-Latenz<br>â€¢ Ziel: <100ms vom Backend-UPDATE bis Pod-Anwendung |

---

## ğŸ¯ Kern-Prinzipien - NACH SPEICHER-BEREICHEN

| Prinzip | Regel | Warum? | Beispiel | Anti-Pattern |
|---------|-------|--------|----------|--------------|
| **PostgreSQL = Source of Truth** | Alle Configs â†’ DB (immer) | Audit, Backup, Migration | â€¢ `service_configs` Tabelle<br>â€¢ `config_history` (Audit-Log)<br>â€¢ pg_dump = alle Configs exportiert | âŒ Configs nur in Redis (nicht persistent)<br>âŒ Configs nur in etcd (kein Audit) |
| **Redis = Hot-Reload Channel** | Config-Ã„nderung â†’ PUBLISH | Echtzeit (<100ms), Multi-Pod Sync | â€¢ `PUBLISH config:ai:threshold "version=5"`<br>â€¢ Alle AI-Pods empfangen gleichzeitig<br>â€¢ Kein Polling, kein Restart | âŒ DB Polling alle 5s (Delay + Last)<br>âŒ ConfigMap Ã¤ndern â†’ Pod neu starten (Downtime) |
| **etcd = K8s-Ressourcen ONLY** | Nur CPU, Memory, Storage, Network | K8s-intern, nicht fÃ¼r Apps | â€¢ `ResourceQuota` (cpu, memory, storage)<br>â€¢ `NetworkPolicy` (deny-all)<br>â€¢ `RoleBinding` (RBAC) | âŒ App-Configs in etcd (kein Audit)<br>âŒ User-Daten in etcd (1.5 MB Limit) |
| **Separation by Type** | **App-Config** â†’ PostgreSQL+Redis<br>**K8s-Ressourcen** â†’ PostgreSQL+etcd | Klare Trennung | â€¢ **App:** AI-Threshold, Email-Retries<br>â€¢ **K8s:** CPU-Quota, Storage-Limit | âŒ Alles in einem System mischen |

---

## ğŸ“Š Visuelle Ãœbersicht: Wo liegt was?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL (App-DB)                                        â”‚
â”‚  â”œâ”€ organizations (Tenant-Metadaten)                        â”‚
â”‚  â”œâ”€ projects (Business-Daten)                               â”‚
â”‚  â”œâ”€ notes (User-Daten)                                      â”‚
â”‚  â”œâ”€ service_configs (App-Configs + K8s-Ressourcen-Mirror)  â”‚
â”‚  â”œâ”€ config_history (Audit-Log: wer, wann, was)             â”‚
â”‚  â””â”€ quota_changes (FinOps: CPU/Memory/Storage Historie)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“ (speichert + notifiziert)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis (Hot-Reload Channel)                                 â”‚
â”‚  â”œâ”€ Channels: config:ai:*, config:email:*, config:api:*    â”‚
â”‚  â”œâ”€ TLS verschlÃ¼sselt (rediss://)                          â”‚
â”‚  â””â”€ ACL: nur SUBSCRIBE erlaubt, keine Secrets              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“ (SUBSCRIBE)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pod RAM (Service Memory)                                   â”‚
â”‚  â”œâ”€ self.threshold = 0.90  (Hot-Reload <100ms)             â”‚
â”‚  â”œâ”€ Warm-Load beim Start (alle Configs aus DB)             â”‚
â”‚  â””â”€ Reconcile alle 5-10 min (falls PUBLISH verpasst)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  etcd (K8s Control Plane)                                   â”‚
â”‚  â”œâ”€ /registry/namespaces/org-acme                          â”‚
â”‚  â”œâ”€ /registry/resourcequotas/org-acme (CPU, Memory, Storage)â”‚
â”‚  â”œâ”€ /registry/networkpolicies/org-acme (deny-all)          â”‚
â”‚  â””â”€ /registry/rbac/rolebindings/org-acme (admin)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ MINI-CHECKLIST (Sofort nutzbar)

| # | Guardrail | Beschreibung | Wo implementieren? |
|---|-----------|--------------|-------------------|
| **1** | **Idempotenz & SAGA** | Operation-ID in DB + K8s-Annotation, Status `PENDING/COMMITTED/FAILED`, kompensierende LÃ¶schung bei Fehler | Backend API |
| **2** | **Namespace-Gate** | Kyverno/OPA Policy blockt Pods bis Label `isolation-ready=true` gesetzt ist | Cluster-Policy |
| **3** | **RLS aktiv** | Row-Level Security auf PostgreSQL-Ebene, automatische Tenant-Isolation | PostgreSQL |
| **4** | **Config-Versionierung** | Monotone Version-Nummer, Pub/Sub trÃ¤gt nur org_id + key + version (kein Value) | DB Schema + Backend |
| **5** | **Redis-HÃ¤rtung** | TLS verschlÃ¼sselt, ACL-basierte Zugriffsrechte, keine Secrets in Topics, Warm-Load + Reconcile | Redis Config + Deployment |
| **6** | **FinOps-Tabellen** | `quota_changes` Tabelle mit effective_at, JOIN mit Prometheus-Metriken fÃ¼r Kosten-Reports | PostgreSQL + Prometheus |
| **7** | **JTI-Denylist** | JWT-ID in Denylist fÃ¼r Sofort-Widerruf bei Token-Compromise | Redis/PostgreSQL |
| **8** | **PITR-Runbook** | WAL-Archiving aktiv, dokumentierter Restore-Prozess mit 5-Minuten-RPO | PostgreSQL Config + Doku |
| **9** | **Reconcile-Loop** | Alle 5-10 min: PrÃ¼fe DB-Version vs. lokale Config-Version, lade nach bei Drift | Pod Background-Thread |
| **10** | **FinOps-Transparenz** | UI zeigt "Neue Quota gilt ab Restart", `effective_at` Timestamp fÃ¼r Abrechnungs-Genauigkeit | UI + Billing-System |

---

## ğŸ“š Dokumentation

- **[Architecture Guide](/docs/architecture/ARCHITECTURE.md)** - Enterprise-Grade Referenz-Architektur (10/10 QualitÃ¤t)
- **[Quickstart](/docs/quickstart/Quickstart.md)** - Setup-Guide und Troubleshooting
- **[Roadmap](/ROADMAP.md)** - Phasen-Checklisten und Fortschritt

---

## ğŸš€ Quick Start

```bash
# Phase 1: Lokale Entwicklung (kind cluster)
./setup-template/setup-phase1.sh

# Status prÃ¼fen
kubectl get pods -A
kind get clusters
```

---

## ğŸ› ï¸ Tech Stack

### **Kern-Infrastruktur**
- **Kubernetes:** kind (lokal), AKS/EKS/GKE (Cloud)
- **GitOps:** Argo CD, Kustomize
- **Datenbank:** PostgreSQL (StatefulSet)
- **Cache:** Redis (Hot-Reload Config, Pub/Sub)
- **Secrets:** External Secrets Operator â†’ Azure Key Vault/AWS Secrets Manager/HashiCorp Vault

### **Sicherheit**
- **Image Signing:** Cosign (keyless OIDC/KMS/Vault)
- **Policy Engine:** Kyverno/OPA Gatekeeper
- **Network:** NetworkPolicies (deny-all baseline)
- **RBAC:** Multi-Tenant-Isolation pro Namespace

### **Observability**
- **Metriken:** kube-prometheus-stack (Prometheus + Grafana)
- **Logs:** Loki
- **Traces:** Tempo/OpenTelemetry Collector
- **Dashboards:** SLO Burn Rate, Certificate Expiry, External Probe Health

---

## ğŸ¯ Use Cases

âœ… **Multi-Tenant SaaS-Plattformen** (wie Azure DevOps, GitLab, Shopify)  
âœ… **AI/ML-Plattformen** mit Hot-Reload Model-Configs  
âœ… **Developer-Plattformen** mit Self-Service Projekt-Erstellung  
âœ… **Enterprise-Grade Infrastruktur** (ISO 27001, NIS2, SOC 2 ready)

---

## ğŸ“„ Lizenz

MIT License - siehe [LICENSE](LICENSE)

---

## ğŸ¤ Contributing

Dies ist ein AI-agent-freundliches Template. Alle Code, Docs und Commits mÃ¼ssen in **Englisch** sein.

**Update [`.github/copilot-instructions.md`](.github/copilot-instructions.md)** bei strukturellen Ã„nderungen!
